---
layout: post
title: "elk部署"
categories: elasticsearch logstash kibana
tags: elk logstash kibana
---

* content
{:toc}

## 1.ELK部署架构

​	**一、概述**

ELK 已经成为目前最流行的集中式日志解决方案，它主要是由Beats、Logstash、Elasticsearch、Kibana等组件组成，来共同完成实时日志的收集，存储，展示等一站式的解决方案。本文将会介绍ELK常见的架构以及相关问题解决。




1. Filebeat：Filebeat是一款轻量级，占用服务资源非常少的数据收集引擎，它是ELK家族的新成员，可以代替Logstash作为在应用服务器端的日志收集引擎，支持将收集到的数据输出到Kafka，Redis等队列。

 

2. Logstash：数据收集引擎，相较于Filebeat比较重量级，但它集成了大量的插件，支持丰富的数据源收集，对收集的数据可以过滤，分析，格式化日志格式。

 

3. Elasticsearch：分布式数据搜索引擎，基于Apache Lucene实现，可集群，提供数据的集中式存储，分析，以及强大的数据搜索和聚合功能。

 

4. 4Kibana：数据的可视化平台，通过该web平台可以实时的查看 Elasticsearch 中的相关数据，并提供了丰富的图表统计功能。

**二、ELK常见部署架构**

**2.1 Logstash作为日志收集器**

这种架构是比较原始的部署架构，在各应用服务器端分别部署一个Logstash组件，作为日志收集器，然后将Logstash收集到的数据过滤、分析、格式化处理后发送至Elasticsearch存储，最后使用Kibana进行可视化展示，这种架构不足的是：Logstash比较耗服务器资源，所以会增加应用服务器端的负载压力。
![img](http://mmbiz.qpic.cn/mmbiz_png/icNyEYk3VqGk2JcFsJS8uM1z0uczq4ApHzXRQ0J6YhHib8ZH8vbvqLEQz7kjmdGjZcUpaibxs7g5icKVMFP8zjibgCg/0?wx_fmt=png)

 

**2.2 Filebeat作为日志收集器**

该架构与第一种架构唯一不同的是：应用端日志收集器换成了Filebeat，Filebeat轻量，占用服务器资源少，所以使用Filebeat作为应用服务器端的日志收集器，一般Filebeat会配合Logstash一起使用，这种部署方式也是目前最常用的架构。

 

![img](http://mmbiz.qpic.cn/mmbiz_png/icNyEYk3VqGk2JcFsJS8uM1z0uczq4ApHDfbTWAiaNq7UoIgCLRtO9UMXXlTog2diajJGV15tqLMFudG9J86msMMQ/0?wx_fmt=png)

 

**2.3 引入缓存队列的部署架构**

该架构在第二种架构的基础上引入了Kafka消息队列（还可以是其他消息队列），将Filebeat收集到的数据发送至Kafka，然后在通过Logstasth读取Kafka中的数据，这种架构主要是解决大数据量下的日志收集方案，使用缓存队列主要是解决数据安全与均衡Logstash与Elasticsearch负载压力。

 

 

![img](http://mmbiz.qpic.cn/mmbiz_png/icNyEYk3VqGk2JcFsJS8uM1z0uczq4ApHGn4mJQWMtkCEeXBAKdTuFcBkEAWJGIYnuegTlrnIQZXWBEtZQ1hXsQ/0?wx_fmt=png)

 

**2.4 以上三种架构的总结**

第一种部署架构由于资源占用问题，现已很少使用，目前使用最多的是第二种部署架构，至于第三种部署架构个人觉得没有必要引入消息队列，除非有其他需求，因为在数据量较大的情况下，Filebeat 使用压力敏感协议向 Logstash 或 Elasticsearch 发送数据。如果 Logstash 正在繁忙地处理数据，它会告知 Filebeat 减慢读取速度。拥塞解决后，Filebeat 将恢复初始速度并继续发送数据。

本文采用第二种方案


**三、问题及解决方案**

**问题：如何实现日志的多行合并功能？**

系统应用中的日志一般都是以特定格式进行打印的，属于同一条日志的数据可能分多行进行打印，那么在使用ELK收集日志的时候就需要将属于同一条日志的多行数据进行合并。

**解决方案：使用Filebeat或Logstash中的multiline多行合并插件来实现**

 

在使用multiline多行合并插件的时候需要注意，不同的ELK部署架构可能multiline的使用方式也不同，如果是本文的第一种部署架构，那么multiline需要在Logstash中配置使用，如果是第二种部署架构，那么multiline需要在Filebeat中配置使用，无需再在Logstash中配置multiline。

1、multiline在Filebeat中的配置方式：

 

> filebeat.prospectors:
>     \-
>        paths:
>           \- /home/project/elk/logs/test.log
>        input_type: log 
>        multiline:
>             pattern: '^\['
>             negate: true
>             match: after
> output:
>    logstash:
>       hosts: ["localhost:5044"]

 

> - pattern：正则表达式
> - negate：默认为false，表示匹配pattern的行合并到上一行；true表示不匹配pattern的行合并到上一行
> - match：after表示合并到上一行的末尾，before表示合并到上一行的行首

 

如：

 

> pattern: '\['
> negate: true
> match: after

该配置表示将不匹配pattern模式的行合并到上一行的末尾

2、multiline在Logstash中的配置方式

 

> input {
>   beats {
>     port => 5044
>   }
> }
>
> filter {
>   multiline {
>     pattern => "%{LOGLEVEL}\s*\]"
>     negate => true
>     what => "previous"
>   }
> }
>
> output {
>   elasticsearch {
>     hosts => "localhost:9200"
>   }
> }

 

> （1）Logstash中配置的what属性值为previous，相当于Filebeat中的after，Logstash中配置的what属性值为next，相当于Filebeat中的before。
> （2）pattern => "%{LOGLEVEL}\s*\]" 中的LOGLEVEL是Logstash预制的正则匹配模式，预制的还有好多常用的正则匹配模式，详细请看：https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns

 

**问题：如何将Kibana中显示日志的时间字段替换为日志信息中的时间？**

默认情况下，我们在Kibana中查看的时间字段与日志信息中的时间不一致，因为默认的时间字段值是日志收集时的当前时间，所以需要将该字段的时间替换为日志信息中的时间。

**解决方案：使用grok分词插件与date时间格式化插件来实现**

在Logstash的配置文件的过滤器中配置grok分词插件与date时间格式化插件，如：

 

> input {
>   beats {
>     port => 5044
>   }
> }
>
> filter {
>   multiline {
>     pattern => "%{LOGLEVEL}\s*\]\[%{YEAR}%{MONTHNUM}%{MONTHDAY}\s+%{TIME}\]"
>     negate => true
>     what => "previous"
>   }
>
>   grok {
>     match => [ "message" , "(?<customer_time>%{YEAR}%{MONTHNUM}%{MONTHDAY}\s+%{TIME})" ]
>   }
>
>   date {
>         match => ["customer_time", "yyyyMMdd HH:mm:ss,SSS"] //格式化时间
>         target => "@timestamp" //替换默认的时间字段
>   }
> }
>
> output {
>   elasticsearch {
>     hosts => "localhost:9200"
>   }
> }

 

如要匹配的日志格式为：“[DEBUG][20170811 10:07:31,359][DefaultBeanDefinitionDocumentReader:106] Loading bean definitions”，解析出该日志的时间字段的方式有：

① 通过引入写好的表达式文件，如表达式文件为customer_patterns，内容为：
CUSTOMER_TIME %{YEAR}%{MONTHNUM}%{MONTHDAY}\s+%{TIME}

 

> **注：**内容格式为：[自定义表达式名称] [正则表达式]

 

然后logstash中就可以这样引用：

 

> filter {
>   grok {
>       patterns_dir => ["./customer-patterms/mypatterns"] //引用表达式文件路径
>       match => [ "message" , "%{CUSTOMER_TIME:customer_time}" ] //使用自定义的grok表达式
>   }
> }

 

② 以配置项的方式，规则为：(?<自定义表达式名称>正则匹配规则)，如：

 

> filter {
>   grok {
>     match => [ "message" , "(?<customer_time>%{YEAR}%{MONTHNUM}%{MONTHDAY}\s+%{TIME})" ]
>   }
> }

 

**问题：如何在Kibana中通过选择不同的系统日志模块来查看数据**

一般在Kibana中显示的日志数据混合了来自不同系统模块的数据，那么如何来选择或者过滤只查看指定的系统模块的日志数据？

**解决方案：新增标识不同系统模块的字段或根据不同系统模块建ES索引**

1、新增标识不同系统模块的字段，然后在Kibana中可以根据该字段来过滤查询不同模块的数据，这里以第二种部署架构讲解，在Filebeat中的配置内容为：

 

> filebeat.prospectors:
>     \-
>        paths:
>           \- /home/project/elk/logs/account.log
>        input_type: log 
>        multiline:
>             pattern: '^\['
>             negate: true
>             match: after
>        fields: //新增log_from字段
>          log_from: account
>
> ​    \-
> ​       paths:
> ​          \- /home/project/elk/logs/customer.log
> ​       input_type: log 
> ​       multiline:
> ​            pattern: '^\['
> ​            negate: true
> ​            match: after
> ​       fields:
> ​         log_from: customer
> output:
>    logstash:
> ​      hosts: ["localhost:5044"]

 

> 通过新增：log_from字段来标识不同的系统模块日志

 

2、根据不同的系统模块配置对应的ES索引，然后在Kibana中创建对应的索引模式匹配，即可在页面通过索引模式下拉框选择不同的系统模块数据。

 

这里以第二种部署架构讲解，分为两步：

 

① 在Filebeat中的配置内容为：

 

> filebeat.prospectors:
>     \-
>        paths:
>           \- /home/project/elk/logs/account.log
>        input_type: log 
>        multiline:
>             pattern: '^\['
>             negate: true
>             match: after
>        document_type: account
>
> ​    \-
> ​       paths:
> ​          \- /home/project/elk/logs/customer.log
> ​       input_type: log 
> ​       multiline:
> ​            pattern: '^\['
> ​            negate: true
> ​            match: after
> ​       document_type: customer
> output:
>    logstash:
> ​      hosts: ["localhost:5044"]

 

通过document_type来标识不同系统模块

② 修改Logstash中output的配置内容为：

 

> output {
>   elasticsearch {
>     hosts => "localhost:9200"
>     index => "%{type}"
>   }
> }


在output中增加index属性，%{type}表示按不同的document_type值建ES索引


**四、总结**


本文主要介绍了ELK实时日志分析的三种部署架构，以及不同架构所能解决的问题，这三种架构中第二种部署方式是时下最流行也是最常用的部署方式，最后介绍了ELK作在日志分析中的一些问题与解决方案，说在最后，ELK不仅仅可以用来作为分布式日志数据集中式查询和管理，还可以用来作为项目应用以及服务器资源监控等场景，更多内容请看官网。


> **出处：https://my.oschina.net/feinik/blog/1580625**


## 2.elasticsearch

elasticsearch运行需要java

 yum install java

[root@zys-yunwei ~]# java -version
openjdk version "1.8.0_242"
OpenJDK Runtime Environment (build 1.8.0_242-b08)
OpenJDK 64-Bit Server VM (build 25.242-b08, mixed mode)

下载中心

https://elasticsearch.cn/download/

**下载elasticsearch**

https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.6.1-x86_64.rpm

**安装**

 rpm -ivh elasticsearch-7.6.1-x86_64.rpm 

**配置**

vi /etc/elasticsearch/elasticsearch.yml 

```
cluster.initial_master_nodes: ["server1"]
cluster.name: zy-application
node.name: server1
#path.data: /storage/elasticsearch/
#path.logs: /storage/elasticsearch/
#bootstrap.mlockall: true
network.host: 0.0.0.0
http.port: 9200
http.cors.enabled: true
http.cors.allow-origin: "*"
```

**错误**

[2020-03-20T18:04:40,144][ERROR][o.e.b.Bootstrap          ] [server1] node validation exception
[1] bootstrap checks failed
[1]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured

 解决：

vi /etc/elasticsearch/elasticsearch.yml 

cluster.initial_master_nodes: ["server1"]

**启动**

systemctl start elasticsearch

## 3.elasticsearch-head（选配）

### 3.1安装nodejs

curl --silent --location https://rpm.nodesource.com/setup_10.x | sudo bash

 yum install  nodejs

添加镜像源

npm install -g cnpm --registry=https://registry.npm.taobao.org

### **3.2 安装grunt** 

cnpm install -g grunt-cli

### 3.3 安装elasticsearch-head

**下载**

下载地址：https://github.com/mobz/elasticsearch-head/archive/v5.0.0.tar.gz

**解压**

执行命令：

tar -zxvf elasticsearch-head-5.0.0.tar.gz -C /usr/local/

ln -s /usr/local/elasticsearch-head-5.0.0/ /usr/local/elasticsearch-head

**配置**

vi /usr/local/elasticsearch-head/Gruntfile.js

修改：
​                connect: {

​                        server: {

​                                options: {

​                                        hostname: '0.0.0.0',

​                                        port: 9100,

​                                        base: '.',

​                                        keepalive: true

​                                }

​                        }

​                }

**安装**

yum install -y bzip2

cd /usr/local/elasticsearch-head

cnpm install

**启动**

cd /usr/local/elasticsearch-head

nohup grunt server >> /var/log/elasticsearch/elasticsearch-head.log 2>&1 &

## 4.kibana（选配）

**rpm安装**

 rpm -ivh kibana-7.6.1-x86_64.rpm

**配置**

 mkdir /var/log/kibana/

chown -R  kibana kibana

 vi /etc/kibana/kibana.yml

```
#监听端口
server.port: 5601
#监听地址
server.host: "192.168.107.170"
#elasticsearch服务器地址
elasticsearch.hosts: ["http://192.168.107.170:9200"]
#修改为中文
i18n.locale: "zh-CN"
logging.dest: "/var/log/kibana/kibana.log"
```

**启动**

```
systemctl start kibana
```



## 5.采集nginx日志为例

### 5.1 filebeat

**安装filebeat服务**

**下载**

https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.6.1-x86_64.rpm

**安装**

```
rpm -ivh filebeat-7.6.1-x86_64.rpm
```

 **配置文件**

vi /etc/filebeat/filebeat.yml

```
#=========================== Filebeat inputs =============================
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /usr/local/nginx/logs/proxy.log
  fields:
    logtype: nginx-proxy
    #logtype在es中以filed.logtype的形式展示
  #fields_under_root: true
  #如果开启fields_under_roo，logtype在es中以logtype的形式展示，注意logstash的条件匹配if [fields][logtype] == "nginx-proxy" 
- type: log
  enabled: true
  paths:
    - /usr/local/nginx/logs/error.log
  fields:
    logtype: nginx-error
  #fields_under_root: true
#我们把nginx的access日志和error两个日志加入elk做分析    
    
#================================ Outputs =====================================

# Configure what output to use when sending the data collected by the beat.
#关闭往Elasticsearch推送，我们让logstash去往Elasticsearch推送
#-------------------------- Elasticsearch output ------------------------------
output.elasticsearch:
  # Array of hosts to connect to.
  #hosts: ["localhost:9200"]

  # Protocol - either `http` (default) or `https`.
  #protocol: "https"

  # Authentication credentials - either API key or username/password.
  #api_key: "id:api_key"
  #username: "elastic"
  #password: "changeme"
  
  
  #----------------------------- Logstash output --------------------------------
  #开启往logstash推送
  output.logstash:
  # The Logstash hosts
  hosts: ["192.168.107.170:5044"]

  # Optional SSL. By default is off.
  # List of root certificates for HTTPS server verifications
  #ssl.certificate_authorities: ["/etc/pki/root/ca.pem"]

  # Certificate for SSL client authentication
  #ssl.certificate: "/etc/pki/client/cert.pem"

  # Client Certificate Key
  #ssl.key: "/etc/pki/client/cert.key"
```



**启动**

systemctl start filebeat

### 5.2 logstash	

**安装**

rpm  -ivh logstash-7.6.1.rpm

**定义nginx日志格式**

参考[nginx日志规范](../_posts/2020-04-02-nginx日志规范.md)

**配置**

vim /etc/logstash/conf.d/nginx-log.conf

```
#输入
input {
    #file {
    #    #日志路径
    #    path => "/usr/local/nginx/logs/access.log"
    #    #类型，自定义，在进行多个日志收集存储时可以通过该项进行判断输出
    #    type => "nginx"
    #    #logstash 从什么位置开始读取文件数据，默认是结束位置，也就是说 logstash 进程会以类似 tail -F 的形式运行。如果你是要导入原有数据，把这个设定改成 "beginning"，logstash 进程就从头开始读取，类似 less +F 的形式运行。
    #    start_position => "beginning"
    #    #logstash 每隔多久检查一次被监听文件状态（是否有更新），默认是 1 秒
    #    stat_interval => "2"
    #}
    beats {
        port => 5044
        #在es中type字段为nginx
        type => "nginx"
    }
}

    
#过滤
filter {
    if [fields][logtype] == "nginx-proxy" {
        grok {
            match => { "message" => "%{IPV4:remote_ip}:%{POSINT:remote_port} (%{USERNAME:user}|-) \[%{HTTPDATE:timestamp}\] \"(?:%{WORD:http_method} %{WORD:scheme}://%{IPORHOST:http_host}%{NOTSPACE:request_uri}(?: HTTP/%{NUMBER:httpversion})?)\" (%{NUMBER:http_status}) (%{NUMBER:request_time}) (%{NUMBER:request_length}|-) (%{NUMBER:body_bytes_sent}|-) (%{QUOTEDSTRING:http_referrer}|-) (%{QUOTEDSTRING:user_agent}) \"(%{HOSTPORT:upstream_addr}|-)\" (%{NUMBER:upstream_status}|-) (%{NUMBER:upstream_response_time}|-) (%{{FORWORD:x_forword_for}|-)" }
            #message已经分割了，把重复的message删除
            remove_field => ["message"]
            #删除系统添加的我们不需要的字段
            remove_field => ["agent","ecs","host"]
        }
        date {
                match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
                target => "@timestamp"
        }
        mutate {
                remove_field => ["timestamp"]
        }
        geoip {
                source => "remote_ip"
        }
    }
    if [fields][logtype] == "nginx-error" {
        grok {
            match => { "message" => "(?<timestamp>%{YEAR}[./-]%{MONTHNUM}[./-]%{MONTHDAY}[- ]%{TIME}) \[%{LOGLEVEL:severity}\] %{POSINT:pid}#%{NUMBER}: %{GREEDYDATA:errormessage}(?:, client: (?<client>%{IP}|%{HOSTNAME}))(?:, server: %{IPORHOST:server})?(?:, request: %{QS:request})?(?:, upstream: \"%{URI:upstream}\")?(?:, host: %{QS:host})?(?:, referrer: \"%{URI:referrer}\")?" }
        }
    }
}

#输出
output {
    elasticsearch {
        #elasticsearch服务器地址
        hosts => ["192.168.107.170:9200"]
        #索引名称
        index => "logstash-%{type}-%{+YYYY.MM.dd}"
    }
}
```

